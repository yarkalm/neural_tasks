{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yarkalm/machinelearning/blob/main/Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ienafXjojyM"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UXDX-NS1trq"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/вдудь.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ3iEyPC2Uin"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSIkpT1E2Wj-",
        "outputId": "c41be9ac-cdf3-44c9-e8b4-a0eed1ee4ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  426304\n",
            "Total Vocab:  101\n"
          ]
        }
      ],
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNgN3fhT2Zjt",
        "outputId": "f6a6923b-71b9-41b1-d017-73e36aaca198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  426204\n"
          ]
        }
      ],
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHP__k9q2fve"
      },
      "outputs": [],
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn-gmm87eEym",
        "outputId": "be51e23d-4839-420d-813d-a8d19487ea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426204, 100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st0N9-hu2hbQ"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "m03YW3RlCi0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a099aa53-0706-422e-e434-430c7ca84fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 100, 256)          264192    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 86)                22102     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 811,606\n",
            "Trainable params: 811,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylKYlGUq2lHH"
      },
      "outputs": [],
      "source": [
        "filepath=\"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCIP9PEe2meH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X, y, epochs=15, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "while history.history['loss'][-1]>1.5:\n",
        "  print(i)\n",
        "  history = model.fit(X, y, epochs=1, batch_size=64, callbacks=callbacks_list)\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W0cp3KJiEn-",
        "outputId": "776cf201-cb47-45be-cae1-a4a35f89000c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6705\n",
            "Epoch 1: loss improved from 1.67186 to 1.67041, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6704.hdf5\n",
            "6660/6660 [==============================] - 126s 19ms/step - loss: 1.6704\n",
            "2\n",
            "6660/6660 [==============================] - ETA: 0s - loss: 1.6666\n",
            "Epoch 1: loss improved from 1.67041 to 1.66658, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6666.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6666\n",
            "3\n",
            "6658/6660 [============================>.] - ETA: 0s - loss: 1.6651\n",
            "Epoch 1: loss improved from 1.66658 to 1.66516, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6652.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6652\n",
            "4\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6646\n",
            "Epoch 1: loss improved from 1.66516 to 1.66459, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6646.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6646\n",
            "5\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6623\n",
            "Epoch 1: loss improved from 1.66459 to 1.66231, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6623.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6623\n",
            "6\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6611\n",
            "Epoch 1: loss improved from 1.66231 to 1.66106, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6611.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6611\n",
            "7\n",
            "6657/6660 [============================>.] - ETA: 0s - loss: 1.6583\n",
            "Epoch 1: loss improved from 1.66106 to 1.65826, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6583.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6583\n",
            "8\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6575\n",
            "Epoch 1: loss improved from 1.65826 to 1.65745, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6574.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6574\n",
            "9\n",
            "6659/6660 [============================>.] - ETA: 0s - loss: 1.6585\n",
            "Epoch 1: loss did not improve from 1.65745\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6585\n",
            "10\n",
            "6660/6660 [==============================] - ETA: 0s - loss: 1.6550\n",
            "Epoch 1: loss improved from 1.65745 to 1.65497, saving model to /content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6550.hdf5\n",
            "6660/6660 [==============================] - 125s 19ms/step - loss: 1.6550\n",
            "11\n",
            "3165/6660 [=============>................] - ETA: 1:05 - loss: 1.6536"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "best = 3.0\n",
        "p = Path(\"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights\")\n",
        "for file in p.rglob(\"*\"):\n",
        "  if float(str(file)[73:79]) <= best:\n",
        "    best = float(str(file)[73:79])\n",
        "  else:\n",
        "    print(file)\n",
        "    os.remove(file)\n",
        "for file in p.rglob(\"*\"):\n",
        "  if str(file) != f\"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--{best}.hdf5\":\n",
        "    os.remove(file)\n",
        "print(f\"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--{best}.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFle1auRzTd",
        "outputId": "4d2eff24-9b31-4bcd-e41d-3d40655a5e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--1.6719.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = f\"/content/drive/MyDrive/Colab Notebooks/МИИиНС/Generator/weights/weights--{best}.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "Dp3aX9zbYlCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "60ZvjnzyY0Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "#start = numpy.random.randint(0, len(dataX)-1)\n",
        "#pattern = dataX[start]\n",
        "\n",
        "pattern = [1]*100\n",
        "string = list(input(\"Input: \").lower()[0:100])\n",
        "for char in range(len(string)):\n",
        "  pattern[-len(string)+char] = (char_to_int[string[char]])\n",
        "print(pattern)\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(200):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVJkjfV8YYGb",
        "outputId": "bf60b67e-3214-4e52-ee8e-5c1ebddc8a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: У меня был одногруппник рэпер — Славик.\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 81, 1, 74, 67, 75, 93, 1, 63, 89, 73, 1, 76, 66, 75, 76, 65, 78, 81, 77, 77, 75, 70, 72, 1, 78, 91, 77, 67, 78, 1, 97, 1, 79, 73, 62, 64, 70, 72, 14]\n",
            "Seed:\n",
            "\"                                                              у меня был одногруппник рэпер — славик. \"\n",
            "\n",
            "\n",
            "— ну это было в том числе и тебе не понимаете, что ты просто сейчас не просто сейчас не просто сейчас не просто самое классных меняши.\n",
            "\n",
            "— а так в какой-то меня он выложил самое классно.\n",
            "\n",
            "— ну это бы\n",
            "Done.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12CdBBYOHeQzWwGSu1IiqYtHOAXTUqNtB",
      "authorship_tag": "ABX9TyNFOo+qe0xZljg5naVaSkRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}